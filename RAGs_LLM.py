from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.llms import HuggingFacePipeline
from transformers import pipeline

# --- CONFIGURATION ---
PDF_PATH = r"Medical Knowledge Document.pdf"
VECTOR_DB_PATH = r"faiss_index"
MODEL_NAME = "tiiuae/falcon-rw-1b"  # ‡∏´‡∏£‡∏∑‡∏≠ "tiiuae/falcon-7b-instruct"

# --- 1. ‡πÇ‡∏´‡∏•‡∏î PDF ---
loader = PyPDFLoader(PDF_PATH)
documents = loader.load()

# --- 2. ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ---
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
docs = text_splitter.split_documents(documents)

# --- 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Embedding ---
embedding_model = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

# --- 4. ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store ---
try:
    db = FAISS.load_local(VECTOR_DB_PATH, embedding_model)
    print("‚úÖ Loaded FAISS from disk.")
except:
    db = FAISS.from_documents(docs, embedding_model)
    db.save_local(VECTOR_DB_PATH)
    print("‚úÖ FAISS created and saved.")

# --- 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á Retriever ‡πÅ‡∏ö‡∏ö MMR ---
retriever = db.as_retriever(search_type="mmr", search_kwargs={"k": 2, "fetch_k": 5})

# --- 6. ‡πÉ‡∏ä‡πâ HuggingFacePipeline LLM ---
hf_pipe = pipeline(
    "text2text-generation",
    model=MODEL_NAME,
    max_length=2000,
    # ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ token ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏ï‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á pipeline ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô:
    # use_auth_token='hf_...'
)
llm = HuggingFacePipeline(pipeline=hf_pipe)

# --- 7. ‡∏™‡∏£‡πâ‡∏≤‡∏á RAG Chain ---
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    return_source_documents=True,
)

# --- 8. ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ---
query = "What is CARDIOVASCULAR DISEASES?"
result = qa_chain.invoke(query)

# --- 9. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ---
print("\nüìå Answer:")
print(result["result"])

print("\nüìÑ Sources:")
for i, doc in enumerate(result["source_documents"]):
    print(f"\n--- Document {i+1} ---")
    print(doc.page_content)
